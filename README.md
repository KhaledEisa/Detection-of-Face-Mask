# State-of-the-Art Face Mask Detection System ğŸ­ğŸ¤–

A professional-grade face mask detection system using modern deep learning techniques with **real datasets**.

## ğŸš€ Features

- **ğŸ§  Multiple Architectures**: EfficientNet, ResNet50V2, MobileNetV3
- **ğŸ“Š Professional Training**: Transfer learning, data augmentation, class balancing
- **ğŸ” Smart Dataset Analysis**: Automatic dataset structure detection
- **ğŸ“ˆ Comprehensive Evaluation**: Accuracy, precision, recall, confusion matrices
- **âš¡ Real-time Inference**: Live webcam detection
- **ğŸ’¾ Model Persistence**: Save and load trained models
- **ğŸ¯ Optimized Parameters**: Automatic parameter suggestion based on dataset size

## ğŸ“ Project Structure

```
face-mask-detection/
â”œâ”€â”€ face_mask_detection_sota.py    # Main training script
â”œâ”€â”€ dataset_setup.py               # Dataset analysis helper
â”œâ”€â”€ quick_inference.py              # Quick testing script
â”œâ”€â”€ requirements.txt                # Dependencies
â””â”€â”€ README.md                      # This file
```

## ğŸ› ï¸ Installation

1. **Install dependencies:**
```bash
pip install -r requirements.txt
```

2. **Prepare your dataset** (one of these structures):

**Option A: Pre-split dataset**
```
your_dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ mask/
â”‚   â””â”€â”€ no_mask/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ mask/
â”‚   â””â”€â”€ no_mask/
â””â”€â”€ test/
    â”œâ”€â”€ mask/
    â””â”€â”€ no_mask/
```

**Option B: Simple structure (auto-split)**
```
your_dataset/
â”œâ”€â”€ mask/
â””â”€â”€ no_mask/
```

## ğŸ¯ Quick Start

### 1. Analyze Your Dataset
```bash
python dataset_setup.py path/to/your/dataset
```

This will:
- âœ… Analyze dataset structure
- âœ… Count images per class  
- âœ… Check class balance
- âœ… Suggest optimal training parameters
- âœ… Generate training command

### 2. Train the Model

Use the suggested command from step 1, or manually:

```bash
python face_mask_detection_sota.py \
    --data_dir "path/to/your/dataset" \
    --architecture efficientnet \
    --img_size 224 \
    --batch_size 32 \
    --epochs 50 \
    --fine_tune_epochs 20
```

### 3. Test Your Model

**Webcam testing:**
```bash
python quick_inference.py --webcam
```

**Single image testing:**
```bash
python quick_inference.py --image your_photo.jpg
```

## ğŸ§  Model Architectures

| Architecture | Best For | Parameters | Speed |
|--------------|----------|------------|-------|
| **MobileNetV3** | Small datasets, Mobile deployment | ~5M | âš¡âš¡âš¡ |
| **EfficientNet** | Balanced performance | ~4M | âš¡âš¡ |
| **ResNet50V2** | Large datasets, High accuracy | ~23M | âš¡ |

## ğŸ“Š Training Process

### Phase 1: Transfer Learning (50 epochs)
- âœ… Freeze base model weights
- âœ… Train custom classification head
- âœ… Learning rate: 0.001

### Phase 2: Fine-tuning (20 epochs)  
- âœ… Unfreeze all layers
- âœ… Fine-tune entire model
- âœ… Lower learning rate: 0.0001

### Advanced Features:
- ğŸ”„ **Data Augmentation**: Rotation, zoom, flip, brightness
- âš–ï¸ **Class Balancing**: Automatic class weight calculation
- ğŸ“‰ **Early Stopping**: Prevent overfitting
- ğŸ“ˆ **Learning Rate Scheduling**: Adaptive learning rate
- ğŸ’¾ **Model Checkpointing**: Save best model automatically

## ğŸ“ˆ Performance Monitoring

The system automatically generates:

- **ğŸ“Š Training History**: Accuracy, loss, precision, recall plots
- **ğŸ¯ Confusion Matrix**: Detailed classification results  
- **ğŸ“‹ Classification Report**: Per-class metrics
- **ğŸ“ Training Log**: CSV file with epoch-by-epoch metrics
- **âš™ï¸ Model Configuration**: JSON file with training parameters

## ğŸ® Command Reference

### Training Commands

**Basic training:**
```bash
python face_mask_detection_sota.py --data_dir your_dataset
```

**Custom parameters:**
```bash
python face_mask_detection_sota.py \
    --data_dir your_dataset \
    --architecture resnet \
    --img_size 256 \
    --batch_size 16 \
    --epochs 100 \
    --fine_tune_epochs 30
```

### Inference Commands

**Live webcam:**
```bash
python quick_inference.py --webcam
```

**Specific model:**
```bash
python quick_inference.py --webcam --model my_custom_model.h5
```

**Image testing:**
```bash
python quick_inference.py --image test_photo.jpg --model best_face_mask_model.h5
```

### Dataset Analysis

**Full analysis:**
```bash
python dataset_setup.py your_dataset_path
```

## ğŸ”§ Optimization Tips

### For Small Datasets (<1000 images):
- Use **MobileNet** architecture
- Smaller image size (128x128)
- More data augmentation
- Lower batch size (16)

### For Large Datasets (>10000 images):
- Use **ResNet** architecture  
- Higher image size (256x256)
- Larger batch size (64+)
- More training epochs

### For GPU Memory Issues:
- Reduce batch size
- Use MobileNet architecture
- Reduce image size
- Enable mixed precision training

## ğŸ“‹ Expected Results

With a **good dataset** (2000+ balanced images):

| Metric | Expected Range |
|--------|----------------|
| **Accuracy** | 92-98% |
| **Precision** | 90-97% |
| **Recall** | 90-97% |
| **Training Time** | 30-60 minutes |

## ğŸ” Troubleshooting

### Common Issues:

**"No module named tensorflow"**
```bash
pip install tensorflow==2.15.0
```

**"Out of memory" errors**
```bash
# Reduce batch size
python face_mask_detection_sota.py --batch_size 8
```

**Low accuracy**
- Check dataset quality and balance
- Increase training epochs
- Try different architecture
- Add more data augmentation

**Webcam not working**
```bash
# Try different camera index
python quick_inference.py --webcam --camera 1
```

## ğŸ“Š File Outputs

After training, you'll get:
- âœ… `best_face_mask_model.h5` - Best model (highest validation accuracy)
- âœ… `face_mask_model_final.h5` - Final model (last epoch)
- âœ… `training_history.png` - Training curves visualization
- âœ… `confusion_matrix.png` - Classification results
- âœ… `training_log.csv` - Detailed training metrics
- âœ… `training_config.json` - Training parameters
- âœ… `suggested_training_command.txt` - Optimal command for your dataset

## ğŸ­ Real-Time Detection Features

- **ğŸ¯ Accurate Detection**: State-of-the-art model performance
- **âš¡ Fast Processing**: Optimized for real-time use
- **ğŸ“Š Confidence Scores**: See prediction confidence
- **ğŸ¨ Visual Feedback**: Color-coded bounding boxes
- **ğŸ“¸ Screenshot Capture**: Save results with 's' key
- **ğŸ”„ Easy Controls**: 'q' to quit, 's' to save

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

## ğŸ“œ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- **TensorFlow Team** for the deep learning framework
- **OpenCV Community** for computer vision tools
- **EfficientNet Authors** for the efficient architecture
- **Transfer Learning Research** for enabling fast training

---

ğŸ‰ **Ready to train with your real dataset!** Follow the Quick Start guide above.
